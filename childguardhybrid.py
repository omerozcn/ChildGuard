# -*- coding: utf-8 -*-
"""ChildGuardHybrid

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aAe70f_NfoLBEi81KJLbC_vsyeMq8f-o
"""

# ============================================================
# 0) Gerekli Kütüphaneler
# ============================================================
print("Kütüphaneler yükleniyor...")
!pip install transformers datasets accelerate joblib seaborn -U > /dev/null
print("Yükleme tamamlandı.")

import pandas as pd
import numpy as np
import re
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import shutil
from google.colab import files

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.utils import class_weight, resample
from sklearn.metrics import (accuracy_score, confusion_matrix,
                             precision_recall_fscore_support,
                             classification_report)

from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import hstack, csr_matrix

from transformers import BertTokenizer, TFBertForSequenceClassification

# ============================================================
# 1) Genel Ayarlar
# ============================================================
DATASET_PATH = "ChildGuard_Cleaned.csv"
TEXT = "text"
TARGET = "actual_class"
AGE_GROUP_COL = "Age_Group"

MAX_LEN = 128
BATCH_SIZE = 16

AGE_GROUPS = {
    "Teen":       ["teen"],
    "Pre-Teen":   ["pre-teen", "preteen"],
    "Younger":    ["younger", "child"]
}

# Modelleri toplamak için klasör
!mkdir -p final_models

# ============================================================
# 2) Dataset Yükleme ve Temizleme
# ============================================================
print("\nDataset yükleniyor...")
df_raw = pd.read_csv(DATASET_PATH, encoding="cp1252")
df_raw = df_raw.dropna(subset=[TEXT, TARGET, AGE_GROUP_COL])

def clean_text_bert_optimized(text):
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+", "", text)
    text = re.sub(r"@\w+", "", text)
    text = re.sub(r"[^a-zA-Z0-9\s!?.,]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

df_raw[TEXT] = df_raw[TEXT].apply(clean_text_bert_optimized)

# ============================================================
# 3) Tokenizer
# ============================================================
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

def encode(texts):
    return tokenizer(texts, truncation=True, padding=True, max_length=MAX_LEN)

# ============================================================
# 4) BERT Modelleri (Eğitim, Tahmin ve CM Çizimi)
# ============================================================
history = {}
results_bert = []

for group_name, patterns in AGE_GROUPS.items():
    print("\n" + "="*60)
    print(f" YAŞ GRUBU: {group_name}")
    print("="*60)

    pattern_regex = "|".join(patterns)
    df = df_raw[df_raw[AGE_GROUP_COL].str.contains(pattern_regex, case=False, na=False)].copy()

    if len(df) < 50:
        print(f"{group_name} için yetersiz veri, atlanıyor.")
        continue

    X = df[TEXT].tolist()
    y = df[TARGET].astype(int).tolist()

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)

    # Oversampling
    train_df = pd.DataFrame({'text': X_train, 'label': y_train})
    df_maj = train_df[train_df.label == 0]
    df_min = train_df[train_df.label == 1]
    df_min_up = resample(df_min, replace=True, n_samples=len(df_maj), random_state=42)
    df_up = pd.concat([df_maj, df_min_up]).sample(frac=1, random_state=42)

    X_train_up, y_train_up = df_up['text'].tolist(), df_up['label'].tolist()

    # TF Datasets
    train_ds = tf.data.Dataset.from_tensor_slices((dict(encode(X_train_up)), y_train_up)).shuffle(2000).batch(BATCH_SIZE)
    val_ds = tf.data.Dataset.from_tensor_slices((dict(encode(X_val)), y_val)).batch(BATCH_SIZE)
    test_ds = tf.data.Dataset.from_tensor_slices((dict(encode(X_test)), y_test)).batch(BATCH_SIZE)

    model = TFBertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2, from_pt=True)
    model.compile(optimizer=tf.keras.optimizers.Adam(2e-5),
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])

    early_stop = tf.keras.callbacks.EarlyStopping(monitor="val_accuracy", patience=1, restore_best_weights=True)
    model.fit(train_ds, validation_data=val_ds, epochs=3, callbacks=[early_stop], verbose=1)

    # Prediction & Threshold Tuning
    logits = model.predict(test_ds).logits
    probs = tf.nn.softmax(logits, axis=1).numpy()[:, 1]

    best_f1 = -1; best_thr = 0.5
    for thr in np.linspace(0.3, 0.7, 20):
        y_p = (probs >= thr).astype(int)
        f1 = precision_recall_fscore_support(y_test, y_p, average="binary")[2]
        if f1 > best_f1:
            best_f1 = f1; best_thr = thr; best_y_pred = y_p

    # Kaydet
    save_path = f"final_models/bert_{group_name.lower()}"
    model.save_pretrained(save_path)
    tokenizer.save_pretrained(save_path)

    history[group_name] = {'y_true': y_test, 'y_pred': best_y_pred, 'threshold': best_thr}
    results_bert.append({"Age Group": group_name, "Accuracy": accuracy_score(y_test, best_y_pred), "F1": best_f1})

# ============================================================
# 5) KLASİK MODEL: Logistic Regression + GridSearchCV
# ============================================================
print("\n\n" + "="*60)
print(" KLASİK MODEL: Logistic Regression + GridSearchCV")
print("="*60)

df_classic = df_raw.copy()
df_classic["text_len"] = df_classic[TEXT].str.len()
df_classic["word_cnt"] = df_classic[TEXT].str.split().str.len()

X_meta = df_classic[[AGE_GROUP_COL, "text_len", "word_cnt"]]
y = df_classic[TARGET].astype(int)

X_m_train, X_m_test, y_train, y_test, t_train, t_test = train_test_split(
    X_meta, y, df_classic[TEXT], test_size=0.2, random_state=42, stratify=y
)

vectorizer = TfidfVectorizer(max_features=5000, min_df=5)
X_train_tfidf = vectorizer.fit_transform(t_train)
X_test_tfidf = vectorizer.transform(t_test)

train_cat = pd.get_dummies(X_m_train[AGE_GROUP_COL], prefix="AgeGroup")
test_cat = pd.get_dummies(X_m_test[AGE_GROUP_COL], prefix="AgeGroup").reindex(columns=train_cat.columns, fill_value=0)

X_train_final = hstack([X_train_tfidf, csr_matrix(X_m_train[["text_len", "word_cnt"]].values), csr_matrix(train_cat.values)])
X_test_final = hstack([X_test_tfidf, csr_matrix(X_m_test[["text_len", "word_cnt"]].values), csr_matrix(test_cat.values)])

param_grid_lr = {'C': [0.1, 1, 10, 100], 'solver': ['liblinear'], 'max_iter': [1000]}
grid_lr = GridSearchCV(LogisticRegression(class_weight="balanced", random_state=42),
                       param_grid_lr, cv=5, scoring='f1', n_jobs=-1)
grid_lr.fit(X_train_final, y_train)

best_lr = grid_lr.best_estimator_
joblib.dump(best_lr, "final_models/logistic_regression_model.pkl")
joblib.dump(vectorizer, "final_models/tfidf_vectorizer.pkl")

y_pred_lr = best_lr.predict(X_test_final)

# ============================================================
# 6) GÖRSELLEŞTİRME VE ANALİZ (Confusion Matrixler)
# ============================================================
print("\n===== ANALİZ SONUÇLARI VE GÖRSELLEŞTİRME =====")

# 1. BERT Modelleri Confusion Matrixleri
for g_name, data in history.items():
    cm = confusion_matrix(data['y_true'], data['y_pred'])
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=["Safe", "Targeted"], yticklabels=["Safe", "Targeted"])
    plt.title(f"BERT Confusion Matrix: {g_name} (Thr: {data['threshold']:.2f})")
    plt.ylabel('Gerçek')
    plt.xlabel('Tahmin')
    plt.show()

# 2. Logistic Regression Confusion Matrix
cm_lr = confusion_matrix(y_test, y_pred_lr)
plt.figure(figsize=(6, 5))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Greens',
            xticklabels=["Safe", "Targeted"], yticklabels=["Safe", "Targeted"])
plt.title("Logistic Regression (Tuned) Confusion Matrix - Genel")
plt.ylabel('Gerçek')
plt.xlabel('Tahmin')
plt.show()

# 3. Özet Tablo
print("\n--- BERT MODELLERİ ÖZET ---")
print(pd.DataFrame(results_bert).to_string(index=False))

print("\n--- LOGISTIC REGRESSION (TUNED) GENEL RAPOR ---")
print(classification_report(y_test, y_pred_lr))

# ============================================================
# 7) PAKETLEME VE İNDİRME
# ============================================================
print("\nModeller paketleniyor...")
shutil.make_archive('ChildGuard_Complete_Bundle', 'zip', 'final_models')
files.download('ChildGuard_Complete_Bundle.zip')
print("✅ İşlem başarıyla tamamlandı. ZIP dosyanız indiriliyor.")